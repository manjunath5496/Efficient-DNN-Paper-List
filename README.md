<h2> Efficient DNN Paper List </h2>



<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(1).pdf" style="text-decoration:none;">Neural Architecture Search: A Survey</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(2).pdf" style="text-decoration:none;">Efficient Progressive Neural Architecture Search</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(3).pdf" style="text-decoration:none;">Complementary Binary Quantization for Joint Multiple Indexing</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(4).pdf" style="text-decoration:none;">Efficient DNN Neuron Pruning by Minimizing Layer-wise Nonlinear Reconstruction Error</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(5).pdf" style="text-decoration:none;">Accelerating Convolutional Networks via Global and Dynamic Filter Pruning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(6).pdf" style="text-decoration:none;">Progressive Blockwise Knowledge Distillation for Neural Network Acceleration</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(7).pdf" style="text-decoration:none;">Where to Prune: Using LSTM to Guide End-to-end Pruning</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(8).pdf" style="text-decoration:none;"> Structured Probabilistic Pruning for Convolutional Neural Network Acceleration </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(9).pdf" style="text-decoration:none;">Distilling the Knowledge in a Neural Network</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(10).pdf" style="text-decoration:none;">Do Deep Convolutional Nets Really Need to be Deep and Convolutional?</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(11).pdf" style="text-decoration:none;">Variational Dropout Sparsifies Deep Neural Networks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(12).pdf" style="text-decoration:none;">Like What You Like: Knowledge Distill via Neuron Selectivity Transfer</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(13).pdf" style="text-decoration:none;">Learning Intrinsic Sparse Structures within Long Short-Term Memory</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(14).pdf" style="text-decoration:none;">PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(15).pdf" style="text-decoration:none;">NISP: Pruning Networks using Neuron Importance Score Propagation</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(16).pdf" style="text-decoration:none;">Learning Global Additive Explanations for Neural Nets Using Model Distillation</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(17).pdf" style="text-decoration:none;">Regularized Evolution for Image Classifier Architecture Search</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(18).pdf" style="text-decoration:none;">Efficient Sparse-Winograd Convolutional Neural Networks</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(19).pdf" style="text-decoration:none;">Attention-Based Guided Structured Sparsity of Deep Neural Networks</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(20).pdf" style="text-decoration:none;">Born-Again Neural Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(21).pdf" style="text-decoration:none;">A Neurobiological Evaluation Metric for Neural Network Model Search</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(22).pdf" style="text-decoration:none;">HAQ: Hardware-Aware Automated Quantization with Mixed Precision</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(23).pdf" style="text-decoration:none;">Auto-DeepLab:
Hierarchical Neural Architecture Search for Semantic Image Segmentation</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(24).pdf" style="text-decoration:none;">Towards Federated Learning at Scale: System Design</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(25).pdf" style="text-decoration:none;">The State of Sparsity in Deep Neural Networks</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(26).pdf" style="text-decoration:none;">Partial Order Pruning: for Best Speed/Accuracy Trade-off in Neural Architecture Search</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(27).pdf" style="text-decoration:none;">MFAS: Multimodal Fusion Architecture Search</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(28).pdf" style="text-decoration:none;">Luck Matters: Understanding Training Dynamics of Deep ReLU Networks</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(29).pdf" style="text-decoration:none;">Filter Grafting for Deep Neural Networks </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(30).pdf" style="text-decoration:none;">Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(31).pdf" style="text-decoration:none;">Learning Filter Pruning Criteria
for Deep Convolutional Neural Networks Acceleration</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(32).pdf" style="text-decoration:none;">DropNet: Reducing Neural Network Complexity via Iterative Pruning</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(33).pdf" style="text-decoration:none;">Deep Neural Networks for Object Detection</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(34).pdf" style="text-decoration:none;">Coreset-Based Neural Network Compression</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(35).pdf" style="text-decoration:none;">A theory of learning from different domains</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(36).pdf" style="text-decoration:none;">"Learning-Compression" Algorithms for Neural Net Pruning</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(37).pdf" style="text-decoration:none;">Compressing Neural Networks with the Hashing Trick</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(38).pdf" style="text-decoration:none;">Context-aware Deep Feature Compression for High-speed Visual Tracking</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(39).pdf" style="text-decoration:none;">Contrastive Representation Distillation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(40).pdf" style="text-decoration:none;">Low-rank Compression of Neural Nets: Learning the Rank of Each Layer</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(41).pdf" style="text-decoration:none;">ChamNet: Towards Efficient Network Design through Platform-Aware Model Adaptation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(42).pdf" style="text-decoration:none;">Learning to generate chairs with convolutional neural networks</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(43).pdf" style="text-decoration:none;">Dynamic Model Pruning with Feedback</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(44).pdf" style="text-decoration:none;">Structured Multi-Hashing for Model Compression</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(45).pdf" style="text-decoration:none;">Ensemble Distribution Distillation</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(46).pdf" style="text-decoration:none;">Discrete Model Compression with Resource Constraint for Deep Neural Networks</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(47).pdf" style="text-decoration:none;">Multi-Dimensional Pruning: A Unified Framework for Model Compression</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(48).pdf" style="text-decoration:none;">Online Knowledge Distillation via Collaborative Learning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(49).pdf" style="text-decoration:none;">The Knowledge Within: Methods for Data-Free Model Compression</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(50).pdf" style="text-decoration:none;">Learning Filter Pruning Criteria
for Deep Convolutional Neural Networks Acceleration</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(51).pdf" style="text-decoration:none;">Creating Something from Nothing:
Unsupervised Knowledge Distillation for Cross-Modal Hashing</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(52).pdf" style="text-decoration:none;">A Diversity-Penalizing Ensemble Training Method for Deep Learning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(53).pdf" style="text-decoration:none;">Low-rank Compression of Neural Nets: Learning the Rank of Each Layer</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(54).pdf" style="text-decoration:none;">Knowledge Consistency between Neural Networks and Beyond</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(55).pdf" style="text-decoration:none;">Structured Compression by Weight Encryption for Unstructured Pruning and Quantization</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(56).pdf" style="text-decoration:none;">Few Sample Knowledge Distillation for Efficient Network Compression </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(57).pdf" style="text-decoration:none;">GAN Compression: Efficient Architectures for Interactive Conditional GANs</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(58).pdf" style="text-decoration:none;">Group Sparsity: The Hinge Between Filter Pruning and Decomposition for Network Compression</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(59).pdf" style="text-decoration:none;">HRank: Filter Pruning using High-Rank Feature Map</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(60).pdf" style="text-decoration:none;">Neural Network Pruning with Residual-Connections and Limited-Data</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(61).pdf" style="text-decoration:none;">ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(62).pdf" style="text-decoration:none;">Discrimination-aware Channel Pruning for Deep Neural Networks</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(63).pdf" style="text-decoration:none;">Frequency-Domain Dynamic Pruning for Convolutional Neural Networks</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(64).pdf" style="text-decoration:none;">Variational Mutual Information Distillation for Transfer Learning</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(65).pdf" style="text-decoration:none;">Bayesian Dark Knowledge </a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(66).pdf" style="text-decoration:none;">CNNpack: Packing Convolutional Neural Networks in the Frequency Domain</a></li> 
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(67).pdf" style="text-decoration:none;">Sobolev Training for Neural Networks</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(68).pdf" style="text-decoration:none;">Learning the Structure of Deep
  Architectures Using l<sub>1</sub> Regularization</a></li> 
 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(69).pdf" style="text-decoration:none;">Heterogeneous Knowledge Distillation using Information Flow Modeling</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(70).pdf" style="text-decoration:none;">Picking Winning Tickets Before Training by Preserving Gradient Flow</a></li> 
  
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(71).pdf" style="text-decoration:none;">SNAS: Stochastic Neural Architecture Search</a></li>
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(72).pdf" style="text-decoration:none;">A Systematic DNN Weight Pruning Framework using Alternating Direction Method of Multipliers</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(73).pdf" style="text-decoration:none;">Towards Evolutionary Compression</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(74).pdf" style="text-decoration:none;">APQ: Joint Search for Network Architecture, Pruning and Quantization Policy</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(75).pdf" style="text-decoration:none;">MineGAN: effective knowledge transfer from GANs to target domains with few images</a></li>                        
<li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(76).pdf" style="text-decoration:none;">Neural Networks Are More Productive Teachers Than Human Raters: Active Mixup for Data-Efficient Knowledge Distillation from a Blackbox Model</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(77).pdf" style="text-decoration:none;">Automatic Neural Network Compression by Sparsity-Quantization Joint Learning: A Constrained Optimization-based Approach</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(78).pdf" style="text-decoration:none;">Distilling Knowledge from Graph Convolutional Networks</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(79).pdf" style="text-decoration:none;">Data-Free Knowledge Amalgamation via Group-Stack Dual-GAN</a></li>


 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(80).pdf" style="text-decoration:none;">Distilling Cross-Task Knowledge via Relationship Matching</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(81).pdf" style="text-decoration:none;">A Gift from Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(82).pdf" style="text-decoration:none;">Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(83).pdf" style="text-decoration:none;">Revisiting Knowledge Distillation via Label Smoothing Regularization</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(84).pdf" style="text-decoration:none;">Regularizing Class-wise Predictions via Self-knowledge Distillation</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(85).pdf" style="text-decoration:none;">Data-Driven Sparse Structure Selection for Deep Neural Networks</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(86).pdf" style="text-decoration:none;">Less is More: Towards Compact CNNs</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Efficient-DNN-Paper-List/blob/master/dnn(87).pdf" style="text-decoration:none;">Towards Effective Low-bitwidth Convolutional Neural Networks</a></li>
  </ul>
  
  
  
